{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5 - Implementation on Ukrainian Dataset\n",
    "We used a Ukrainian trade dataset (`ukraine_trade_data_2018_ontology.csv`) as an input to our function to fully test our product.  \n",
    "\n",
    "This dataset was similar in structure to our training dataset in that it had columns for `COMPANY_NAME`, `COMPANY_ID`, and `DESCRIPTION`.  However there were some elements of the dataset that needed to be fixed before processing. The column names were also different than those of our training dataset, but our product allows for column specification, so this was not an issue.\n",
    "\n",
    "The results were positive!  Although a stronger metric is needed to identify similarity to known arms exporters, our product identified 32 INNs in the 7,326,528 row dataset as having similar text trading patterns as known Russian arms exporters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (20.0.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement dask==2.4.8 (from versions: 0.7.4.linux-x86_64, 0.7.5.linux-x86_64, 0.7.6.linux-x86_64, 0.8.1.macosx-10.5-x86_64, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.3.0, 0.4.0, 0.5.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.8.0, 0.8.1, 0.8.2, 0.9.0, 0.10.0, 0.10.1, 0.10.2, 0.11.0, 0.11.1, 0.12.0, 0.13.0rc1, 0.13.0, 0.14.0, 0.14.1, 0.14.2, 0.14.3, 0.15.0, 0.15.1, 0.15.2, 0.15.3, 0.15.4, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.17.2, 0.17.3, 0.17.4, 0.17.5, 0.18.0, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.19.3, 0.19.4, 0.20.0, 0.20.1, 0.20.2, 1.0.0, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.0, 1.2.1, 1.2.2, 2.0.0, 2.1.0, 2.2.0, 2.3.0, 2.4.0, 2.5.0, 2.5.2, 2.6.0, 2.7.0, 2.8.0, 2.8.1, 2.9.0, 2.9.1, 2.9.2, 2.10.0, 2.10.1, 2.11.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for dask==2.4.8\u001b[0m\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already up-to-date: s3fs in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3fs) (1.14.14)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3fs) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: boto3>=1.9.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3fs) (1.11.14)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.9.91->s3fs) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.11.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.18.1)\n",
      "Requirement already satisfied: pymystem3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pymystem3) (2.20.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->pymystem3) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->pymystem3) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->pymystem3) (2019.9.11)\n",
      "Requirement already satisfied: spacy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.2.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (2.20.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (39.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.43.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.14.1)\n",
      "Requirement already satisfied: pymorphy2==0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.8)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pymorphy2==0.8) (2.4.393442.3710985)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pymorphy2==0.8) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pymorphy2==0.8) (0.6.2)\n",
      "Requirement already satisfied: dask_ml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.2.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (0.24.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (1.1.0)\n",
      "Requirement already satisfied: multipledispatch>=0.4.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (0.5.0)\n",
      "Requirement already satisfied: dask[array,dataframe]>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (2.11.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (0.22.2)\n",
      "Requirement already satisfied: distributed>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (2.11.0)\n",
      "Requirement already satisfied: numba in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (0.38.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (20.1)\n",
      "Requirement already satisfied: dask-glm>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask_ml) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.23.4->dask_ml) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.23.4->dask_ml) (2018.4)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.9.0)\n",
      "Requirement already satisfied: partd>=0.3.10; extra == \"dataframe\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.1.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0; extra == \"dataframe\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn>=0.21->dask_ml) (0.14.1)\n",
      "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (5.0.2)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (1.6.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (5.2)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (0.5.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (39.1.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (6.7)\n",
      "Requirement already satisfied: psutil>=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (5.4.5)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (0.6.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (0.1.3)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (1.5.10)\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from numba->dask_ml) (0.23.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->dask_ml) (2.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->dask_ml) (1.11.0)\n",
      "Requirement already satisfied: locket in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[array,dataframe]>=2.4.0->dask_ml) (0.2.0)\n",
      "Requirement already satisfied: heapdict in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=2.4.0->dask_ml) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "#pip installations - necessary to get notebook to run\n",
    "#update dask\n",
    "!pip install --upgrade pip\n",
    "!pip install dask==2.4.8\n",
    "!pip install fsspec\n",
    "!pip install --upgrade s3fs\n",
    "!pip install numpy\n",
    "!pip install pymystem3\n",
    "!pip install spacy\n",
    "!pip install joblib\n",
    "!pip install pymorphy2==0.8\n",
    "!pip install dask_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/dask/array/random.py:27: FutureWarning: dask.array.random.doc_wraps is deprecated and will be removed in a future version\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "# dataframe\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# DESCRIPTION_GOOD preprocessing\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "#--------#\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "\n",
    "# machine learning/analysis\n",
    "from dask_ml.cluster import KMeans as dask_ml_model # sklearn's skmeans took up too much memory to run.\n",
    "\n",
    "# measuring euclidian distance\n",
    "from scipy.spatial.distance import euclidean, pdist\n",
    "\n",
    "# S3 bucket interaction\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "\n",
    "# Disable warning message related to SettingWithCopyWarning\n",
    "# displays when running final function otherwise\n",
    "pd.options.mode.chained_assignment = None     # default = 'warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stemmer and Russian stopwords for data preprocessing\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "# https://stackoverflow.com/questions/5511708/adding-words-to-nltk-stoplist\n",
    "# add trade-specific stopwords to list\n",
    "newStopWords = ['г', '№', '10', '1', '20', '30', 'кг', '5', 'см',\n",
    "                '100', '80', '2', 'х', 'l', 'м', '00', '000'\n",
    "                '1.27', '2011.10631', '4', '12', '3', 'фр', 'количество',\n",
    "                'становиться', 'мм', 'вид', 'упаковка', 'получать',\n",
    "                'прочий', 'использование', 'масса', 'размер', 'черный',\n",
    "                '6', '8', '7', '50', '40', '25', 'коробка', 'поддон',\n",
    "                'вдоль', '250', '65', '85', '15', '35', '40', '45',\n",
    "                '55', '60', '70', '75', 'м3', '13', '0', '14',\n",
    "                '16', '18', 'm2', 'п', 'р', 'т', 'тип', 'являться',\n",
    "                'размер', 'cm', 'm', '01', '02', '03', '04', '05',\n",
    "                '06', '07', '08', '09', '24', '27']\n",
    "russian_stopwords.extend(newStopWords)\n",
    "\n",
    "#define function for preprocessing text - to be used later in notebook\n",
    "#function will remove Russian stop words and any punctuation not removed in cleaning_trade_data_desc_kmeans.ipynb\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "        and token != \" \" \\\n",
    "        and token.strip() not in punctuation]\n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "\n",
    "# similarity function for euclidian measure at end of main function\n",
    "def similarity_func(u, v):\n",
    "    return 1/(1+euclidean(u,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('s3://ukraine-trade-data/ukraine_trade_data_2018_ontology.csv',dtype={'CONTRACTOR_ADDRESS': 'object', \n",
    "                                                                                       'EXCISE_DUTY_UAH': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRADE_DIRECTION', 'SHIPPER_NAME', 'SHIPPER_EDRPOU',\n",
       "       'DESCRIPTION_GOODS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['TRADE_DIRECTION', 'SHIPPER_NAME', 'SHIPPER_EDRPOU', 'DESCRIPTION_GOODS']]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7326528, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['TRADE_DIRECTION'] == 'EXPORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['TRADE_DIRECTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHIPPER_NAME         object\n",
       "SHIPPER_EDRPOU       object\n",
       "DESCRIPTION_GOODS    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all EDRPOU in ukrainian dataset were floats before we converted them to strings, have '.0' at end\n",
    "# couldn't convert to int because of NaN values, didnt want to lose any data in dataset\n",
    "# .str[:-2] removes last two characters from every string in column, in this case '.0'\n",
    "X['SHIPPER_EDRPOU'] = X['SHIPPER_EDRPOU'].str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHIPPER_NAME</th>\n",
       "      <th>SHIPPER_EDRPOU</th>\n",
       "      <th>DESCRIPTION_GOODS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ТОВАРИСТВО З ОБМЕЖЕНОЮ ВIДПОВIДАЛЬНIСТЮ \"ЕКО С...</td>\n",
       "      <td>40142870</td>\n",
       "      <td>1.МАКУХА СОЄВА НА КОРМА ДЛЯ ТВАРИН - 22000КГ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ПРИВАТНЕ АКЦIОНЕРНЕ ТОВАРИСТВО \"ГРАФІЯ УКРАЇНА\"</td>\n",
       "      <td>2469333</td>\n",
       "      <td>1.ВКЛАДИШІ ДО СИГАРЕТНОЇ ПАЧКИ: IC WI / IC WI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ПРИВАТНЕ АКЦIОНЕРНЕ ТОВАРИСТВО \"НОВИЙ СТИЛЬ\"</td>\n",
       "      <td>32565288</td>\n",
       "      <td>1.ГВИНТ З ЦИЛІНДРИЧНОЮ ГОЛ.ISO 4762-M8X2 0-8.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ТОВАРИСТВО З ОБМЕЖЕНОЮ ВIДПОВIДАЛЬНIСТЮ \"ТАРТУ...</td>\n",
       "      <td>38282429</td>\n",
       "      <td>1. ПЛОДИ СИРІ, ЗАМОРОЖЕНІ, БЕЗ ДОДАВАННЯ ЦУКРУ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ПРИВАТНЕ АКЦIОНЕРНЕ ТОВАРИСТВО \"МАРІУПОЛЬСЬКИЙ...</td>\n",
       "      <td>191129</td>\n",
       "      <td>1.ТРУБА ЕЛЕКТРОЗВАРНА КВАДРАТНОГО ПЕРЕРІЗУ ЗГІ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        SHIPPER_NAME SHIPPER_EDRPOU  \\\n",
       "0  ТОВАРИСТВО З ОБМЕЖЕНОЮ ВIДПОВIДАЛЬНIСТЮ \"ЕКО С...       40142870   \n",
       "1    ПРИВАТНЕ АКЦIОНЕРНЕ ТОВАРИСТВО \"ГРАФІЯ УКРАЇНА\"        2469333   \n",
       "2       ПРИВАТНЕ АКЦIОНЕРНЕ ТОВАРИСТВО \"НОВИЙ СТИЛЬ\"       32565288   \n",
       "3  ТОВАРИСТВО З ОБМЕЖЕНОЮ ВIДПОВIДАЛЬНIСТЮ \"ТАРТУ...       38282429   \n",
       "4  ПРИВАТНЕ АКЦIОНЕРНЕ ТОВАРИСТВО \"МАРІУПОЛЬСЬКИЙ...         191129   \n",
       "\n",
       "                                   DESCRIPTION_GOODS  \n",
       "0       1.МАКУХА СОЄВА НА КОРМА ДЛЯ ТВАРИН - 22000КГ  \n",
       "1  1.ВКЛАДИШІ ДО СИГАРЕТНОЇ ПАЧКИ: IC WI / IC WI ...  \n",
       "2  1.ГВИНТ З ЦИЛІНДРИЧНОЮ ГОЛ.ISO 4762-M8X2 0-8.8...  \n",
       "3  1. ПЛОДИ СИРІ, ЗАМОРОЖЕНІ, БЕЗ ДОДАВАННЯ ЦУКРУ...  \n",
       "4  1.ТРУБА ЕЛЕКТРОЗВАРНА КВАДРАТНОГО ПЕРЕРІЗУ ЗГІ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHIPPER_NAME         1831495\n",
       "SHIPPER_EDRPOU       1831495\n",
       "DESCRIPTION_GOODS    1831495\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export ukraine to S3 bucket\n",
    "# df.to_csv('s3://labs20-arms-bucket/data/ukraine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model, vectorizer, and tokenizer to notebook\n",
    "s3 = boto3.resource('s3')\n",
    "bucket=s3.Bucket('labs20-arms-bucket')\n",
    "\n",
    "# load vectorizer from S3 bucket\n",
    "key = \"vectorizerf.pkl\"\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    bucket.download_fileobj(Fileobj=fp, Key=key)\n",
    "    fp.seek(0)\n",
    "    vectorizer = joblib.load(fp)\n",
    "\n",
    "# load model from S3 bucket\n",
    "key = \"modelf.pkl\"\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    bucket.download_fileobj(Fileobj=fp, Key=key)\n",
    "    fp.seek(0)\n",
    "    model = joblib.load(fp)\n",
    "\n",
    "#load cluster dataset from S3 bucket\n",
    "# drop error column accidentally created in import\n",
    "clusters = pd.read_csv('s3://labs20-arms-bucket/data/armsclustersf.csv')\n",
    "clusters = clusters.drop([clusters.columns[0]], axis='columns')\n",
    "\n",
    "# list of known arms exporters\n",
    "inn_arms_exp_total = ['7718852163',  '7740000090',    '7731084175',  '6161021690',\n",
    "                      '3807002509',  '6672315362',    '7802375335',  '7813132895',  \n",
    "                      '7731280660',  '7303026762',    '5040007594',  '2501002394',  \n",
    "                      '7807343496',  '7731559044',    '5042126251',  '7731595540',    \n",
    "                      '7733018650',  '7722016820',    '7705654132',  '7714336520',    \n",
    "                      '7801074335',  '6229031754',    '7830002462',  '6825000757',  \n",
    "                      '5043000212',  '7802375889',    '5010031470',  '1660249187',  \n",
    "                      '7720015691',  '6154573235',    '5038087144',  '7713006304',  \n",
    "                      '7805326230',  '5023002050',    '4007017378',  '7714013456',  \n",
    "                      '17718852163', '7811406004',    '7702077840',  '7839395419',  \n",
    "                      '7702244226',  '7704721192',    '7731644035',  '7712040285',\n",
    "                      '7811144648',  '4345047310',    '7720066255',  '6607000556',\n",
    "                      '1832090230',  '1835011597',    '3305004083',  '4340000830',\n",
    "                      '5074051432',  '1841015504',    '7105008338',  '7106002829', \n",
    "                      '7704274402',  '5942400228',    '7105514574',  '5012039795', \n",
    "                      '7714733528',  '3904065550',    '6825000757',  '7807343496', \n",
    "                      '7731559044',  '7805231691',    '7704859803',  '0273008320',\n",
    "                      '7704274402',  '2902059091',    '7805034277',  '7727692011',\n",
    "                      '7733759899',  '6154028021',    '7328032711',  '2635002815',\n",
    "                      '5040097816',  '5027033274',    '5250018433',  '5200000046',\n",
    "                      '7743813961',  '7718016666',    '5047118550',  '7704274402']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predictor_function(df, name_column = 'CONSIGNOR_NAME', id_column = 'CONSIGNOR_INN', text_column = 'DESCRIPTION_GOOD',\n",
    "                              invalid_id_terms = ['None', '00', 'ИНН/КПП НЕ О', '0'], min_trades=35, profile_similarity_threshold = .65,\n",
    "                              cluster_columns = ['clust0', 'clust1', 'clust6']):\n",
    "    \"\"\"\n",
    "    function to clean INNs of input dataframe and return Russian arms exporter similarity calculation\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # set column variable\n",
    "        # reduce dataframe so that dataframe only contains columns in columns variable\n",
    "        df = df[[name_column, id_column, text_column]]\n",
    "        \n",
    "        # remove rows from dataset containing INNs of known arms exporters\n",
    "        # check 'INN' column against inn_arms_exp_total list, drop row if there's a match with the list\n",
    "        df = df[~df[id_column].isin(inn_arms_exp_total)]\n",
    "        \n",
    "        # clean INNs\n",
    "        # Create subslice of dataframe for dictionary\n",
    "        dict_df = df[[name_column, id_column]]\n",
    "        # clean columns of dict_df, remove invalid_id_terms from CONSIGNOR_INN column\n",
    "        invalid_id_terms = invalid_id_terms\n",
    "        for term in invalid_id_terms:\n",
    "            dict_df = dict_df[dict_df[id_column] != term]\n",
    "        # drop all null values\n",
    "        dict_df.dropna(inplace=True)\n",
    "        # sort values by 'CONSIGNOR_NAME'\n",
    "        dict_df.sort_values(name_column, inplace = True) \n",
    "        # dropping ALL duplicte 'CONSIGNOR_NAME' values from dictionary\n",
    "        dict_df.drop_duplicates(subset =name_column, keep = 'first', inplace = True) \n",
    "        # create list of 2-item lists: [CONSIGNOR_NAME, CONSIGNOR_INN]\n",
    "        new_list = dict_df.values.tolist()\n",
    "        # create dictionary out of list of lists\n",
    "        # for every list in the list of lists, take the first item in list (CONSIGNOR_NAME)\n",
    "        # and add it to index position of dictionary, take second term ('CONSIGNOR_INN') and add it to value position of dictionary\n",
    "        # cannot use pandas.to_dict() because it adds column names to dictionary; only want indexes/values\n",
    "        new_dict = {t[0]:t[1] for t in new_list}\n",
    "        # map new_dict to 'CONSIGNOR_INN' column of main dataframe\n",
    "        df[id_column] = df[name_column].map(new_dict)\n",
    "\n",
    "        # drop null values\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # remove all rows from list whose total INN count is less than min_trades variable\n",
    "        # way to limit size before processing, weed out INNs that only have a few trades present in dataset\n",
    "        df = df[df.groupby(id_column)[id_column].transform('size') >= min_trades]\n",
    "        \n",
    "        #create list for preprocessed text to be appended to\n",
    "        processed_text_list = []\n",
    "        \n",
    "        #this is the alg to apply preprocessing function to text column\n",
    "        # removed print statement from David's function\n",
    "        for i in range(len(df[text_column])):\n",
    "            x = df[text_column].iloc[i]\n",
    "            if isinstance(x, str):\n",
    "                processed_text_list.append(preprocess_text(x))\n",
    "            else:\n",
    "                processed_text_list.append(preprocess_text(x.astype(str)))\n",
    "            \n",
    "        # convert list of preprocessed text to dataframe\n",
    "        # to be concatenated onto original dataframe\n",
    "        df1 = pd.DataFrame({'PREPROCESSED_TEXT':processed_text_list})\n",
    "        \n",
    "        # reset indices of both dataframes\n",
    "        df1 = df1.reset_index()\n",
    "        df = df.reset_index()\n",
    "        df['index'] = df.index\n",
    "        \n",
    "        # merge preprocessed text to original dataframe\n",
    "        df_merge = pd.concat([df, df1], axis=1, join='inner')\n",
    "        \n",
    "        # drop DESCRIPTION_GOOD column, no longer necessary now that PROCESSED_TEXT column is present\n",
    "        df_merge = df_merge.drop([text_column, 'index'], axis='columns')\n",
    "        \n",
    "        #define variable to feed to TFIDF Vectorizer - 'PROCESSED_TEXT' column of train dataset\n",
    "        text = df_merge['PREPROCESSED_TEXT']\n",
    "        \n",
    "        #transform text with vectorizer\n",
    "        #Converted to Unicode because it will run into an np.nan error. This need to be turned into a unicode string.\n",
    "        sparse = vectorizer.transform(text.values.astype('U'))\n",
    "        \n",
    "        # Get feature names to use as dataframe column headers\n",
    "        dtm = pd.DataFrame(sparse.todense(), columns=vectorizer.get_feature_names())\n",
    "        \n",
    "        # reset indices of both dataframes for merge\n",
    "        # not sure why we had to do this, but running the following three commands gave us the results we wanted\n",
    "        dtm = dtm.reset_index()\n",
    "        df_merge = df_merge.reset_index()\n",
    "        df_merge['index'] = df_merge.index\n",
    "        dtm['index'] = dtm.index\n",
    "        \n",
    "        # merge vectorized word feature matrix with training dataset\n",
    "        df_merge_vector = pd.concat([df_merge, dtm], axis=1, join='inner')\n",
    "        # drop index columns\n",
    "        df_merge_vector = df_merge_vector.drop(columns=['index'])\n",
    "        \n",
    "        # variable manipulation to feed into KMeans model\n",
    "        # pull create variable containing dataframe of vectorized words only, all rows, columns indexed 4 and onward\n",
    "        X = df_merge_vector.drop(columns=[name_column, id_column, 'PREPROCESSED_TEXT'])\n",
    "        \n",
    "        # convert X dataframe into array\n",
    "        # necessary to feed to KMeans model\n",
    "        X_array = X.values\n",
    "        \n",
    "        # fit model on vectorized word array\n",
    "        labels = model.predict(X_array)\n",
    "        \n",
    "        # create 'cluster' column to add to vectorized dataframe\n",
    "        #Glue back to originaal data\n",
    "        df_merge_vector['cluster'] = labels\n",
    "\n",
    "        # extract columns for final analysis\n",
    "        Y = df_merge_vector[[id_column,'cluster']]\n",
    "        \n",
    "        # add column to dataframe for each cluster in model, created with copied values from 'cluster' column\n",
    "        # create 1,0 boolean to check if number in cell is equal to number of cluster, assigns 1s and 0s accordingly\n",
    "        # drop cluster column, no longer necessary now that we have count\n",
    "        for i in range(model.n_clusters):\n",
    "            Y['clust{}'.format(i)] = Y['cluster']\n",
    "            Y['clust{}'.format(i)] = (Y['clust{}'.format(i)] == i) * 1\n",
    "        \n",
    "        # drop 'cluster' column, no longer necessary now that we have total trades per cluster per INN\n",
    "        Y = Y.drop(columns=['cluster'])\n",
    "        \n",
    "        #create column_names variable to filter out CONSIGNER_INN from .groupby() in next step\n",
    "        column_names = Y.drop(columns = [id_column]).columns.tolist()\n",
    "        \n",
    "        #create new dataframe totalling trades per cluster per INN\n",
    "        Y = pd.DataFrame(Y.groupby([Y[id_column]])[column_names].sum()).reset_index()\n",
    "        \n",
    "        # add final tally for known arms exporters\n",
    "        # reset index so known arms exporters are at bottom of dataframe, indexed properly\n",
    "        Y = Y.append(clusters.iloc[0,1:], sort=None).reset_index().drop(columns=['index'])\n",
    "        \n",
    "        # convert all columns except for 'CONSIGNOR_INN' to decimals/percentages of total\n",
    "        Y[column_names] = Y[column_names].div(Y[column_names].sum(axis=1), axis=0)\n",
    "        \n",
    "        # cluster columns\n",
    "        # remove clusters with low percentages for known arms exporters from dataset\n",
    "        cluster_columns = cluster_columns\n",
    "        cluster_columns.insert(0, id_column)\n",
    "        Y = Y[cluster_columns]\n",
    "        \n",
    "        # similarity matrix - create list of p-distance scores using pdistance & euclidian distance\n",
    "        # simply put, it measures how similar two sets if numbers are\n",
    "        # https://stackoverflow.com/questions/35758612/most-efficient-way-to-construct-similarity-matrix\n",
    "        # each row in dataframe will be compared against the bottom row of the dataframe, which contains the totals for knowns arms exporters\n",
    "        pscores=[]\n",
    "        for i in range(len(Y)):\n",
    "            x = pdist([Y.iloc[-1, 1:],Y.iloc[i, 1:]], similarity_func)[0]\n",
    "            pscores.append(x)\n",
    "        \n",
    "        # add pdist_score column to Y dataframe\n",
    "        Y['pdist_score'] = pscores\n",
    "        \n",
    "        # drop control row (known arms exporters totals)\n",
    "        Y = Y.drop(Y.index[-1])\n",
    "        \n",
    "        # create profile_similarity_threshold variable\n",
    "        # if INN's pdist_score >= profile_similarity_threshold, INN will be included in final dataframe\n",
    "        # if INN's pdist_score < profile_similarity_threshold, INN will not be included in final dataframe\n",
    "        Y = Y[Y['pdist_score'] >= profile_similarity_threshold]\n",
    "        \n",
    "        #generate dataframe\n",
    "        return Y\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHIPPER_EDRPOU</th>\n",
       "      <th>clust0</th>\n",
       "      <th>clust1</th>\n",
       "      <th>clust6</th>\n",
       "      <th>pdist_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>2781504255</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>32502825</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>31489175</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>36767366</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>36417791</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.117318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>38884736</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>382272</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>39792657</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>24363204</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.229050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>31804036</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>377511</td>\n",
       "      <td>0.822496</td>\n",
       "      <td>0.177504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>20925875</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>37310549</td>\n",
       "      <td>0.820043</td>\n",
       "      <td>0.179957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>413475</td>\n",
       "      <td>0.818671</td>\n",
       "      <td>0.181329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>23510703</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>33240672</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>37987502</td>\n",
       "      <td>0.791980</td>\n",
       "      <td>0.208020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>382102</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>39695169</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>41330519</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.870267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>30638249</td>\n",
       "      <td>0.752747</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>34589850</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>41633830</td>\n",
       "      <td>0.804245</td>\n",
       "      <td>0.101415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>35947117</td>\n",
       "      <td>0.806387</td>\n",
       "      <td>0.127745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>692096</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SHIPPER_EDRPOU    clust0    clust1  clust6  pdist_score\n",
       "940      2781504255  0.837838  0.162162     0.0     0.860791\n",
       "1834       32502825  0.759494  0.240506     0.0     0.860918\n",
       "1497       31489175  0.761194  0.238806     0.0     0.861515\n",
       "2840       36767366  0.833333  0.166667     0.0     0.862335\n",
       "2755       36417791  0.837989  0.117318     0.0     0.862404\n",
       "3468       38884736  0.766667  0.233333     0.0     0.863279\n",
       "3298         382272  0.829268  0.170732     0.0     0.863586\n",
       "3774       39792657  0.826923  0.173077     0.0     0.864244\n",
       "697        24363204  0.770950  0.229050     0.0     0.864483\n",
       "1587       31804036  0.773869  0.226131     0.0     0.865212\n",
       "3138         377511  0.822496  0.177504     0.0     0.865355\n",
       "383        20925875  0.824859  0.169492     0.0     0.865891\n",
       "3001       37310549  0.820043  0.179957     0.0     0.865894\n",
       "4307         413475  0.818671  0.181329     0.0     0.866172\n",
       "626        23510703  0.785714  0.214286     0.0     0.867365\n",
       "2059       33240672  0.790476  0.209524     0.0     0.867853\n",
       "3214       37987502  0.791980  0.208020     0.0     0.867961\n",
       "3291         382102  0.804348  0.195652     0.0     0.868001\n",
       "3725       39695169  0.794872  0.205128     0.0     0.868107\n",
       "4299       41330519  0.755102  0.040816     0.0     0.870267\n",
       "1226       30638249  0.752747  0.219780     0.0     0.871756\n",
       "2375       34589850  0.816667  0.116667     0.0     0.872738\n",
       "4428       41633830  0.804245  0.101415     0.0     0.876327\n",
       "2654       35947117  0.806387  0.127745     0.0     0.877883\n",
       "4741         692096  0.756098  0.134146     0.0     0.894051"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = process_predictor_function(X, name_column = 'SHIPPER_NAME', id_column = 'SHIPPER_EDRPOU', text_column = 'DESCRIPTION_GOODS',\n",
    "#                               profile_similarity_threshold = .85)\n",
    "test.sort_values(by='pdist_score', ascending=True).tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
