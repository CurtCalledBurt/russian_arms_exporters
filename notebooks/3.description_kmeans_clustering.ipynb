{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3 - KMeans Clustering & Exploratory Analysis\n",
    "Once vectorization is complete, a KMeans clustering model is used to group similar bodies of text together.  Once grouped, we totaled the number of trades per cluster per INN (Russian Tax ID number).   Next, we totaled the number of trades per cluster for all known Russian Arms Exporters, and converted those totals to ratios, where each ratio represents the percentage of trades that fall into that cluser.\n",
    "\n",
    "We are building a 'profile' for known Russian arms exporters.  Based on analysis of the text content of individual trades, known Russian arms exporters can be assigned to  clusters.  Our final product will use this known arms exporter profile to compare against new trade data.  It aims to answer the questions: how many companies trade similar products/in a similar manner as known arms exporters, and how similar are they?\n",
    "\n",
    "It assigns a 'similarity score' for each INN in the dataset using a measure of inverse euclidian distance.  In simpler terms, it checks how 'similar' each group of percentages is to the percentages of all known Russian arms exporters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required pip installations\n",
    "!pip install --upgrade pip\n",
    "!pip install joblib\n",
    "!pip install --upgrade s3fs\n",
    "!pip install googletrans\n",
    "\n",
    "# for dask machine learning cluster\n",
    "!pip install dask-ml\n",
    "!pip install executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "# dataframe\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning/analysis\n",
    "#from sklearn.cluster import KMeans\n",
    "import dask_ml.cluster as dask_ml_model # sklearn's skmeans took up too much memory to run.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# saving model to S3 bucket\n",
    "import tempfile\n",
    "import boto3\n",
    "import joblib\n",
    "\n",
    "# translate results\n",
    "from googletrans import Translator\n",
    "#import executor as e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read df_trade_desc_filt_vector for nlp\n",
    "df = dd.read_csv('s3://labs20-arms-bucket/data/df_train_description_filtered_vectorizedIF2.csv',dtype={'CONSIGNOR_INN': 'object'})\n",
    "#                 dtype={'CONSIGNOR_INN': 'str', 'Unnamed: 0': 'str'}, usecols=range(0, 312))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "# remove all ',' from CONSIGNOR_INN column\n",
    "# somehow was missed in REGEX filter from cleaning_trade_data notebook\n",
    "#df['CONSIGNOR_INN'] = df['CONSIGNOR_INN'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONSIGNOR_NAME</th>\n",
       "      <th>CONSIGNOR_INN</th>\n",
       "      <th>PROCESSED_TEXT</th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>27</th>\n",
       "      <th>848686</th>\n",
       "      <th>88104см</th>\n",
       "      <th>90</th>\n",
       "      <th>...</th>\n",
       "      <th>черновой</th>\n",
       "      <th>швейный</th>\n",
       "      <th>шина</th>\n",
       "      <th>шип</th>\n",
       "      <th>шлифовать</th>\n",
       "      <th>шт</th>\n",
       "      <th>электрический</th>\n",
       "      <th>элемент</th>\n",
       "      <th>этиловый</th>\n",
       "      <th>этиловый спирт</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>АОЧЕРЕПОВЕЦКИЙ ФАНЕРНО-МЕБЕЛЬНЫЙ КОМБИНАТ</td>\n",
       "      <td>3528006408</td>\n",
       "      <td>пиломатериалыдоска еловый picea abies обрезная...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>АО ПИКАЛЁВСКАЯ СОДА</td>\n",
       "      <td>4715022874</td>\n",
       "      <td>сульфат калий калий серонокислый технический к...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ООО ИНТЕР-ТРАНС</td>\n",
       "      <td>6324057625</td>\n",
       "      <td>швеллер бампер ваз 21900280301501 шт</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ООО ЗЕЛЕНЫЙ СВЕТ</td>\n",
       "      <td>3849029492</td>\n",
       "      <td>лесоматериал праспиливать вдольнестроганыенелу...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ОАО АВИАКОМПАНИЯ УРАЛЬСКИЕ АВИАЛИНИИ</td>\n",
       "      <td>6608003013</td>\n",
       "      <td>телефонный проводной трубка сбор связь бортпро...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              CONSIGNOR_NAME CONSIGNOR_INN  \\\n",
       "0  АОЧЕРЕПОВЕЦКИЙ ФАНЕРНО-МЕБЕЛЬНЫЙ КОМБИНАТ    3528006408   \n",
       "1                        АО ПИКАЛЁВСКАЯ СОДА    4715022874   \n",
       "2                            ООО ИНТЕР-ТРАНС    6324057625   \n",
       "3                           ООО ЗЕЛЕНЫЙ СВЕТ    3849029492   \n",
       "4       ОАО АВИАКОМПАНИЯ УРАЛЬСКИЕ АВИАЛИНИИ    6608003013   \n",
       "\n",
       "                                      PROCESSED_TEXT   00   10   11   27  \\\n",
       "0  пиломатериалыдоска еловый picea abies обрезная...  0.0  0.0  0.0  0.0   \n",
       "1  сульфат калий калий серонокислый технический к...  0.0  0.0  0.0  0.0   \n",
       "2               швеллер бампер ваз 21900280301501 шт  0.0  0.0  0.0  0.0   \n",
       "3  лесоматериал праспиливать вдольнестроганыенелу...  0.0  0.0  0.0  0.0   \n",
       "4  телефонный проводной трубка сбор связь бортпро...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   848686  88104см   90  ...  черновой  швейный  шина       шип  шлифовать  \\\n",
       "0     0.0      0.0  0.0  ...       0.0      0.0   0.0  0.360739        0.0   \n",
       "1     0.0      0.0  0.0  ...       0.0      0.0   0.0  0.000000        0.0   \n",
       "2     0.0      0.0  0.0  ...       0.0      0.0   0.0  0.000000        0.0   \n",
       "3     0.0      0.0  0.0  ...       0.0      0.0   0.0  0.000000        0.0   \n",
       "4     0.0      0.0  0.0  ...       0.0      0.0   0.0  0.000000        0.0   \n",
       "\n",
       "         шт  электрический  элемент  этиловый  этиловый спирт  \n",
       "0  0.000000            0.0      0.0       0.0             0.0  \n",
       "1  0.000000            0.0      0.0       0.0             0.0  \n",
       "2  0.604300            0.0      0.0       0.0             0.0  \n",
       "3  0.000000            0.0      0.0       0.0             0.0  \n",
       "4  0.345262            0.0      0.0       0.0             0.0  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframe to memory\n",
    "# allows pandas operations to be performed\n",
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding Data Into the Model\n",
    "Similar to the TfidfVectorizer, our dask_ml_model.KMeans model object must be trained on an array.  In our inital analysis we did not perform hyperparameter tuning, and selected 10 clusters for our KMeans cluster as a default.  Once the array was created, we fit the model on the array, and extracted model.labels_ to use as our cluster names, and added the results to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable manipulation to feed into KMeans model\n",
    "# pull create variable containing dataframe of vectorized words only, all rows, columns indexed 4 and onward\n",
    "X = df.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>27</th>\n",
       "      <th>848686</th>\n",
       "      <th>88104см</th>\n",
       "      <th>90</th>\n",
       "      <th>946288</th>\n",
       "      <th>946388</th>\n",
       "      <th>abies</th>\n",
       "      <th>...</th>\n",
       "      <th>черновой</th>\n",
       "      <th>швейный</th>\n",
       "      <th>шина</th>\n",
       "      <th>шип</th>\n",
       "      <th>шлифовать</th>\n",
       "      <th>шт</th>\n",
       "      <th>электрический</th>\n",
       "      <th>элемент</th>\n",
       "      <th>этиловый</th>\n",
       "      <th>этиловый спирт</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00   10   11   27  848686  88104см   90  946288  946388     abies  ...  \\\n",
       "0  0.0  0.0  0.0  0.0     0.0      0.0  0.0     0.0     0.0  0.433472  ...   \n",
       "1  0.0  0.0  0.0  0.0     0.0      0.0  0.0     0.0     0.0  0.000000  ...   \n",
       "2  0.0  0.0  0.0  0.0     0.0      0.0  0.0     0.0     0.0  0.000000  ...   \n",
       "3  0.0  0.0  0.0  0.0     0.0      0.0  0.0     0.0     0.0  0.000000  ...   \n",
       "4  0.0  0.0  0.0  0.0     0.0      0.0  0.0     0.0     0.0  0.000000  ...   \n",
       "\n",
       "   черновой  швейный  шина       шип  шлифовать        шт  электрический  \\\n",
       "0       0.0      0.0   0.0  0.360739        0.0  0.000000            0.0   \n",
       "1       0.0      0.0   0.0  0.000000        0.0  0.000000            0.0   \n",
       "2       0.0      0.0   0.0  0.000000        0.0  0.604300            0.0   \n",
       "3       0.0      0.0   0.0  0.000000        0.0  0.000000            0.0   \n",
       "4       0.0      0.0   0.0  0.000000        0.0  0.345262            0.0   \n",
       "\n",
       "   элемент  этиловый  этиловый спирт  \n",
       "0      0.0       0.0             0.0  \n",
       "1      0.0       0.0             0.0  \n",
       "2      0.0       0.0             0.0  \n",
       "3      0.0       0.0             0.0  \n",
       "4      0.0       0.0             0.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataframe to confirm its columns only contain word vectors\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8312006, 301)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataframe to confirm its columns only contain word vectors\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X dataframe into array\n",
    "# necessary to feed to KMeans model\n",
    "X_array = X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Model Selection\n",
    "Because sklearn's KMeans module used too much memory, Labs20 group decided to use dask_ml_model from dask.clusters library.  This is because the default initializer for dask_ml_model.KMeans is `k-means||`, compared to `k-means++` from scikit-learn.  `k-means||` is designed to work well in a distributed environment such as SageMaker, whereas `k-means++` reads everything to memeory at once and can cause errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define KMeans model\n",
    "# n_jobs = -1 tells model to use all available processors\n",
    "model = dask_ml_model.KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', copy_x=True, init='k-means||', init_max_iter=None,\n",
       "       max_iter=300, n_clusters=10, n_jobs=1, oversampling_factor=2,\n",
       "       precompute_distances='auto', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on vectorized word array\n",
    "model.fit(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the model was trained on our array of word vectors, we pickled it to our S3 bucket for use in our final product.\n",
    "s3 = boto3.resource('s3')\n",
    "bucket=s3.Bucket('labs20-arms-bucket')\n",
    "key = \"modelf.pkl\"\n",
    "\n",
    "# WRITE/SAVE 'model' to s3 bucket\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    joblib.dump(model, fp, compress=3)\n",
    "    fp.seek(0)\n",
    "    bucket.put_object(Body=fp.read(), Key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test READ/LOAD of model from S3 bucket\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    bucket.download_fileobj(Fileobj=fp, Key=key)\n",
    "    fp.seek(0)\n",
    "    model_load = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', copy_x=True, init='k-means||', init_max_iter=None,\n",
       "       max_iter=300, n_clusters=10, n_jobs=1, oversampling_factor=2,\n",
       "       precompute_distances='auto', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming model saved to S3 bucket is the same as model created in notebook\n",
    "model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', copy_x=True, init='k-means||', init_max_iter=None,\n",
       "       max_iter=300, n_clusters=10, n_jobs=1, oversampling_factor=2,\n",
       "       precompute_distances='auto', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming vmodel saved to S3 bucket is the same as model created in notebook\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONSIGNOR_NAME</th>\n",
       "      <th>CONSIGNOR_INN</th>\n",
       "      <th>PROCESSED_TEXT</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>АОЧЕРЕПОВЕЦКИЙ ФАНЕРНО-МЕБЕЛЬНЫЙ КОМБИНАТ</td>\n",
       "      <td>3528006408</td>\n",
       "      <td>пиломатериалыдоска еловый picea abies обрезная...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>АО ПИКАЛЁВСКАЯ СОДА</td>\n",
       "      <td>4715022874</td>\n",
       "      <td>сульфат калий калий серонокислый технический к...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ООО ИНТЕР-ТРАНС</td>\n",
       "      <td>6324057625</td>\n",
       "      <td>швеллер бампер ваз 21900280301501 шт</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ООО ЗЕЛЕНЫЙ СВЕТ</td>\n",
       "      <td>3849029492</td>\n",
       "      <td>лесоматериал праспиливать вдольнестроганыенелу...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ОАО АВИАКОМПАНИЯ УРАЛЬСКИЕ АВИАЛИНИИ</td>\n",
       "      <td>6608003013</td>\n",
       "      <td>телефонный проводной трубка сбор связь бортпро...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              CONSIGNOR_NAME CONSIGNOR_INN  \\\n",
       "0  АОЧЕРЕПОВЕЦКИЙ ФАНЕРНО-МЕБЕЛЬНЫЙ КОМБИНАТ    3528006408   \n",
       "1                        АО ПИКАЛЁВСКАЯ СОДА    4715022874   \n",
       "2                            ООО ИНТЕР-ТРАНС    6324057625   \n",
       "3                           ООО ЗЕЛЕНЫЙ СВЕТ    3849029492   \n",
       "4       ОАО АВИАКОМПАНИЯ УРАЛЬСКИЕ АВИАЛИНИИ    6608003013   \n",
       "\n",
       "                                      PROCESSED_TEXT  cluster  \n",
       "0  пиломатериалыдоска еловый picea abies обрезная...        5  \n",
       "1  сульфат калий калий серонокислый технический к...        1  \n",
       "2               швеллер бампер ваз 21900280301501 шт        0  \n",
       "3  лесоматериал праспиливать вдольнестроганыенелу...        5  \n",
       "4  телефонный проводной трубка сбор связь бортпро...        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model labels in variable 'labels'\n",
    "labels = model.labels_\n",
    "\n",
    "#Glue back to originaal data\n",
    "df['cluster'] = labels\n",
    "\n",
    "# reduce dataframe to necessary columns, no longer need text now that we have clusters\n",
    "df = df[['CONSIGNOR_NAME', 'CONSIGNOR_INN', 'PROCESSED_TEXT', 'cluster']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframe with cluster assignments to S3 Bucket\n",
    "df.to_csv('s3://labs20-arms-bucket/data/df_train_with_clustersIF2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Analysis\n",
    "Once our model was saved, we recreated the 'tokenize' function and loaded the pickled vectorizer to view the results of our clustering. For some reason we could not load the pickled 'tokenize' function from our S3 bucket, so we had to recreate it each time.  Because the tokenize function was used in our vectorizer, it must be loaded into the memory of the notebook before the vectorizer is loaded from the S3 bucket, otherwise an error message will generate.\n",
    "\n",
    "To see how our model/vectorizer performed we created a for loop that generated the top 10 terms per cluster and translated them to English.  To our delight, the clusters seemed to organize the text corpuses around specific industries; clusters 0, 6, and 7 even displayed words strongly associated with arms exports and heavy machine building!  This is a sign that our model grouped similar trades correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create S3 object\n",
    "s3 = boto3.resource('s3')\n",
    "bucket=s3.Bucket('labs20-arms-bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vectorizer for analysis\n",
    "key = \"vectorizerf.pkl\"\n",
    "# test READ/LOAD of vectorizer from S3 bucket\n",
    "with tempfile.TemporaryFile() as fp:\n",
    "    bucket.download_fileobj(Fileobj=fp, Key=key)\n",
    "    fp.seek(0)\n",
    "    vectorizer = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      "Russian:  шт , English: PCS\n",
      "Russian:  часть , English: part\n",
      "Russian:  ваз , English: vases\n",
      "Russian:  изделие , English: product\n",
      "Russian:  марка , English: mark\n",
      "Russian:  гост , English: guest\n",
      "Russian:  материал , English: material\n",
      "Russian:  назначение , English: appointment\n",
      "Russian:  сталь , English: steel\n",
      "Russian:  вес , English: weight\n",
      "Russian:  новый , English: new\n",
      "Russian:  длина , English: length\n",
      "Russian:  рулон , English: roll\n",
      "Russian:  металл , English: metal\n",
      "Russian:  диаметр , English: diameter\n",
      "Cluster 1:\n",
      "Russian:  содержать , English: contain\n",
      "Russian:  спирт , English: alcohol\n",
      "Russian:  какао , English: cocoa\n",
      "Russian:  этиловый , English: ethyl\n",
      "Russian:  сахар , English: sugar\n",
      "Russian:  этиловый спирт , English: ethanol\n",
      "Russian:  содержание , English: content\n",
      "Russian:  вещество , English: substance\n",
      "Russian:  добавка , English: supplement\n",
      "Russian:  средство , English: means\n",
      "Russian:  изделие , English: product\n",
      "Russian:  жир , English: fat\n",
      "Russian:  добавление , English: addition\n",
      "Russian:  шт , English: PCS\n",
      "Russian:  продукт , English: product\n",
      "Cluster 2:\n",
      "Russian:  мас , English: weight\n",
      "Russian:  содержание , English: content\n",
      "Russian:  сера , English: sulfur\n",
      "Russian:  топливо , English: fuel\n",
      "Russian:  содержание сера , English: sulfur content\n",
      "Russian:  перегоняться , English: distilled\n",
      "Russian:  astm , English: asthma\n",
      "Russian:  метод , English: method\n",
      "Russian:  температура , English: temperature\n",
      "Russian:  цель , English: target\n",
      "Russian:  мазут , English: fuel oil\n",
      "Russian:  менее , English: less\n",
      "Russian:  метод astm , English: astm method\n",
      "Russian:  жидкий , English: liquid\n",
      "Russian:  топливо жидкий , English: liquid fuel\n",
      "Cluster 3:\n",
      "Russian:  розничный , English: retail\n",
      "Russian:  продажа , English: sale\n",
      "Russian:  розничный продажа , English: retail sale\n",
      "Russian:  расфасовывать , English: prepack\n",
      "Russian:  средство , English: means\n",
      "Russian:  лекарственный , English: drug\n",
      "Russian:  расфасовывать розничный , English: packaged retail\n",
      "Russian:  лекарственный средство , English: medicinal agent\n",
      "Russian:  содержать , English: contain\n",
      "Russian:  ветеринария , English: veterinary science\n",
      "Russian:  сильнодействующий , English: potent\n",
      "Russian:  наркотический , English: narcotic\n",
      "Russian:  применяться ветеринария , English: applied veterinary\n",
      "Russian:  наркотический сильнодействующий , English: potent drug\n",
      "Russian:  содержать наркотический , English: containing narcotic\n",
      "Cluster 4:\n",
      "Russian:  трикотажный , English: knitted\n",
      "Russian:  обхват , English: coverage\n",
      "Russian:  вязание , English: knitting\n",
      "Russian:  машинный , English: machine\n",
      "Russian:  машинный вязание , English: knitting machine\n",
      "Russian:  женский , English: female\n",
      "Russian:  нить , English: a thread\n",
      "Russian:  пряжа , English: yarn\n",
      "Russian:  рост , English: height\n",
      "Russian:  грудь , English: chest\n",
      "Russian:  хлопчатобумажный , English: cotton\n",
      "Russian:  обхват грудь , English: chest girth\n",
      "Russian:  хлопчатобумажный пряжа , English: cotton yarn\n",
      "Russian:  одежда , English: clothes\n",
      "Russian:  класс люкс , English: luxury\n",
      "Cluster 5:\n",
      "Russian:  соединение , English: compound\n",
      "Russian:  иметь , English: have\n",
      "Russian:  иметь соединение , English: have a connection\n",
      "Russian:  распиливать , English: saw up\n",
      "Russian:  шип , English: spike\n",
      "Russian:  пиломатериал , English: timber\n",
      "Russian:  соединение шип , English: Tongue\n",
      "Russian:  обыкновенный , English: ordinary\n",
      "Russian:  pinus , English: pinus\n",
      "Russian:  сосна , English: Pine\n",
      "Russian:  sylvestris , English: sylvestris\n",
      "Russian:  гост , English: guest\n",
      "Russian:  доска , English: board\n",
      "Russian:  pinus sylvestris , English: pinus sylvestris\n",
      "Russian:  обыкновенный pinus , English: ordinary pinus\n",
      "Cluster 6:\n",
      "Russian:  предназначать , English: intend\n",
      "Russian:  гражданский , English: civil\n",
      "Russian:  применение , English: application\n",
      "Russian:  бытовой , English: domestic\n",
      "Russian:  назначение , English: appointment\n",
      "Russian:  часть , English: part\n",
      "Russian:  техника , English: equipment\n",
      "Russian:  изделие , English: product\n",
      "Russian:  марка , English: mark\n",
      "Russian:  система , English: system\n",
      "Russian:  лом , English: fracture\n",
      "Russian:  качество , English: quality\n",
      "Russian:  военный , English: military\n",
      "Russian:  электрический , English: electric\n",
      "Russian:  ремонт , English: repairs\n",
      "Cluster 7:\n",
      "Russian:  стальной , English: steel\n",
      "Russian:  марка , English: mark\n",
      "Russian:  пруток , English: bar\n",
      "Russian:  нелегированный , English: unalloyed\n",
      "Russian:  сталь , English: steel\n",
      "Russian:  длина , English: length\n",
      "Russian:  покрытие , English: coating\n",
      "Russian:  шт , English: PCS\n",
      "Russian:  часть , English: part\n",
      "Russian:  изготавливать , English: make\n",
      "Russian:  диаметр , English: diameter\n",
      "Russian:  предназначать , English: intend\n",
      "Russian:  назначение , English: appointment\n",
      "Russian:  иметь , English: have\n",
      "Russian:  содержание , English: content\n",
      "Cluster 8:\n",
      "Russian:  масло , English: oil\n",
      "Russian:  минеральный , English: mineral\n",
      "Russian:  моторный , English: motor\n",
      "Russian:  содержание , English: content\n",
      "Russian:  битуминозный , English: bituminous\n",
      "Russian:  порода , English: breed\n",
      "Russian:  основа , English: basis\n",
      "Russian:  качество , English: quality\n",
      "Russian:  применение , English: application\n",
      "Russian:  нефтяной , English: oil\n",
      "Russian:  мас , English: weight\n",
      "Russian:  двигатель , English: engine\n",
      "Russian:  содержать , English: contain\n",
      "Russian:  жидкий , English: liquid\n",
      "Russian:  пищевой , English: food\n",
      "Cluster 9:\n",
      "Russian:  свежий , English: fresh\n",
      "Russian:  урожай , English: harvest\n",
      "Russian:  год , English: year\n",
      "Russian:  цель , English: target\n",
      "Russian:  расфасовывать , English: prepack\n",
      "Russian:  употребление , English: use\n",
      "Russian:  предназначать , English: intend\n",
      "Russian:  класс , English: class\n",
      "Russian:  гост , English: guest\n",
      "Russian:  мешок , English: bag\n",
      "Russian:  сорт , English: grade\n",
      "Russian:  упаковывать , English: pack\n",
      "Russian:  влажность , English: humidity\n",
      "Russian:  производство , English: production\n",
      "Russian:  00 , English: 00\n"
     ]
    }
   ],
   "source": [
    "# should not run the code many time because the googleapi will give you 'JSONDecodeError: Expecting value: line 1 column 1 (char 0)'\n",
    "# This for loop generates the top 10 terms per cluster and translates them to English\n",
    "translator = Translator()\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(model.n_clusters):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        print(\"Russian:\",' %s' % terms[ind], \", English:\", translator.translate('{}'.format(terms[ind])).text)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4933080\n",
       "5     845003\n",
       "6     524934\n",
       "1     459900\n",
       "3     450046\n",
       "4     384065\n",
       "2     267521\n",
       "8     176743\n",
       "9     141009\n",
       "7     129705\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create listAllcluster list to count the number of trade text corpuses falling into each cluster for all INN numbers.\n",
    "listAllcluster = df.cluster.value_counts()\n",
    "listAllcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Exploration/Known Russian Arms Exporters\n",
    "We now introduce known arms exporter INNs into our analysis.  Unfortunately, the list containing these INNs was manually put together by Labs16 & Labs20 groups, and there is neither a database containing this information or a way to automatically scrape them into our notebook.  The GoogleSpreadsheet containing the running list of known Russian arms exporter INNs can be found here: https://docs.google.com/spreadsheets/d/1-RDS-STLXPQ3tMkPe4hXwt7CL_fM8IrgRWn0uDX6IF4/edit?usp=sharing\n",
    "\n",
    "As stated in Notebook 3, the goal here is to create a 'profile' for known arms exporters.  This is done by totalling the trades per cluster for all INNs.  Once totalled, the known exporter totals dataframe will be exported to our S3 bucket and used as a comparision for our product's final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell saves the string list of known arms exporter inns as variable inn_arms_exp_total\n",
    "inn_arms_exp_total = ['7718852163',  '7740000090',    '7731084175',  '6161021690',\n",
    "                      '3807002509',  '6672315362',    '7802375335',  '7813132895',  \n",
    "                      '7731280660',  '7303026762',    '5040007594',  '2501002394',  \n",
    "                      '7807343496',  '7731559044',    '5042126251',  '7731595540',    \n",
    "                      '7733018650',  '7722016820',    '7705654132',  '7714336520',    \n",
    "                      '7801074335',  '6229031754',    '7830002462',  '6825000757',  \n",
    "                      '5043000212',  '7802375889',    '5010031470',  '1660249187',  \n",
    "                      '7720015691',  '6154573235',    '5038087144',  '7713006304',  \n",
    "                      '7805326230',  '5023002050',    '4007017378',  '7714013456',  \n",
    "                      '17718852163', '7811406004',    '7702077840',  '7839395419',  \n",
    "                      '7702244226',  '7704721192',    '7731644035',  '7712040285',\n",
    "                      '7811144648',  '4345047310',    '7720066255',  '6607000556',\n",
    "                      '1832090230',  '1835011597',    '3305004083',  '4340000830',\n",
    "                      '5074051432',  '1841015504',    '7105008338',  '7106002829', \n",
    "                      '7704274402',  '5942400228',    '7105514574',  '5012039795', \n",
    "                      '7714733528',  '3904065550',    '6825000757',  '7807343496', \n",
    "                      '7731559044',  '7805231691',    '7704859803',  '0273008320',\n",
    "                      '7704274402',  '2902059091',    '7805034277',  '7727692011',\n",
    "                      '7733759899',  '6154028021',    '7328032711',  '2635002815',\n",
    "                      '5040097816',  '5027033274',    '5250018433',  '5200000046',\n",
    "                      '7743813961',  '7718016666',    '5047118550',  '7704274402']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a simple `for` loop to check how many times our known INN numbers appeared in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INN: 7718852163    number of occurances in training dataset (all clusters): 41343\n",
      "INN: 7740000090    number of occurances in training dataset (all clusters): 1588\n",
      "INN: 7731084175    number of occurances in training dataset (all clusters): 1250\n",
      "INN: 6161021690    number of occurances in training dataset (all clusters): 1143\n",
      "INN: 3807002509    number of occurances in training dataset (all clusters): 2489\n",
      "INN: 6672315362    number of occurances in training dataset (all clusters): 579\n",
      "INN: 7802375335    number of occurances in training dataset (all clusters): 118\n",
      "INN: 7813132895    number of occurances in training dataset (all clusters): 212\n",
      "INN: 7731280660    number of occurances in training dataset (all clusters): 492\n",
      "INN: 7303026762    number of occurances in training dataset (all clusters): 461\n",
      "INN: 5040007594    number of occurances in training dataset (all clusters): 167\n",
      "INN: 2501002394    number of occurances in training dataset (all clusters): 243\n",
      "INN: 7807343496    number of occurances in training dataset (all clusters): 18\n",
      "INN: 7731559044    number of occurances in training dataset (all clusters): 721\n",
      "INN: 5042126251    number of occurances in training dataset (all clusters): 17\n",
      "INN: 7731595540    number of occurances in training dataset (all clusters): 105\n",
      "INN: 7733018650    number of occurances in training dataset (all clusters): 31\n",
      "INN: 7722016820    number of occurances in training dataset (all clusters): 34\n",
      "INN: 7705654132    number of occurances in training dataset (all clusters): 78\n",
      "INN: 7714336520    number of occurances in training dataset (all clusters): 16\n",
      "INN: 7801074335    number of occurances in training dataset (all clusters): 4\n",
      "INN: 6229031754    number of occurances in training dataset (all clusters): 200\n",
      "INN: 7830002462    number of occurances in training dataset (all clusters): 40\n",
      "INN: 6825000757    number of occurances in training dataset (all clusters): 19\n",
      "INN: 5043000212    number of occurances in training dataset (all clusters): 8\n",
      "INN: 7802375889    number of occurances in training dataset (all clusters): 10\n",
      "INN: 5010031470    number of occurances in training dataset (all clusters): 2\n",
      "INN: 1660249187    number of occurances in training dataset (all clusters): 10\n",
      "INN: 7720015691    number of occurances in training dataset (all clusters): 5\n",
      "INN: 6154573235    number of occurances in training dataset (all clusters): 1\n",
      "INN: 5038087144    number of occurances in training dataset (all clusters): 1\n",
      "INN: 7713006304    number of occurances in training dataset (all clusters): 1\n",
      "INN: 7805326230    number of occurances in training dataset (all clusters): 1\n",
      "INN: 5023002050    number of occurances in training dataset (all clusters): 3\n",
      "INN: 4007017378    number of occurances in training dataset (all clusters): 1\n",
      "INN: 7714013456    number of occurances in training dataset (all clusters): 0\n",
      "INN: 17718852163    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7811406004    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7702077840    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7839395419    number of occurances in training dataset (all clusters): 118\n",
      "INN: 7702244226    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7704721192    number of occurances in training dataset (all clusters): 1\n",
      "INN: 7731644035    number of occurances in training dataset (all clusters): 162\n",
      "INN: 7712040285    number of occurances in training dataset (all clusters): 124\n",
      "INN: 7811144648    number of occurances in training dataset (all clusters): 0\n",
      "INN: 4345047310    number of occurances in training dataset (all clusters): 12\n",
      "INN: 7720066255    number of occurances in training dataset (all clusters): 0\n",
      "INN: 6607000556    number of occurances in training dataset (all clusters): 13521\n",
      "INN: 1832090230    number of occurances in training dataset (all clusters): 212\n",
      "INN: 1835011597    number of occurances in training dataset (all clusters): 0\n",
      "INN: 3305004083    number of occurances in training dataset (all clusters): 44\n",
      "INN: 4340000830    number of occurances in training dataset (all clusters): 0\n",
      "INN: 5074051432    number of occurances in training dataset (all clusters): 0\n",
      "INN: 1841015504    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7105008338    number of occurances in training dataset (all clusters): 7\n",
      "INN: 7106002829    number of occurances in training dataset (all clusters): 6\n",
      "INN: 7704274402    number of occurances in training dataset (all clusters): 0\n",
      "INN: 5942400228    number of occurances in training dataset (all clusters): 377\n",
      "INN: 7105514574    number of occurances in training dataset (all clusters): 689\n",
      "INN: 5012039795    number of occurances in training dataset (all clusters): 1008\n",
      "INN: 7714733528    number of occurances in training dataset (all clusters): 3333\n",
      "INN: 3904065550    number of occurances in training dataset (all clusters): 0\n",
      "INN: 6825000757    number of occurances in training dataset (all clusters): 19\n",
      "INN: 7807343496    number of occurances in training dataset (all clusters): 18\n",
      "INN: 7731559044    number of occurances in training dataset (all clusters): 721\n",
      "INN: 7805231691    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7704859803    number of occurances in training dataset (all clusters): 0\n",
      "INN: 0273008320    number of occurances in training dataset (all clusters): 536\n",
      "INN: 7704274402    number of occurances in training dataset (all clusters): 0\n",
      "INN: 2902059091    number of occurances in training dataset (all clusters): 3467\n",
      "INN: 7805034277    number of occurances in training dataset (all clusters): 6\n",
      "INN: 7727692011    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7733759899    number of occurances in training dataset (all clusters): 0\n",
      "INN: 6154028021    number of occurances in training dataset (all clusters): 154\n",
      "INN: 7328032711    number of occurances in training dataset (all clusters): 2\n",
      "INN: 2635002815    number of occurances in training dataset (all clusters): 0\n",
      "INN: 5040097816    number of occurances in training dataset (all clusters): 0\n",
      "INN: 5027033274    number of occurances in training dataset (all clusters): 28\n",
      "INN: 5250018433    number of occurances in training dataset (all clusters): 473\n",
      "INN: 5200000046    number of occurances in training dataset (all clusters): 5\n",
      "INN: 7743813961    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7718016666    number of occurances in training dataset (all clusters): 2\n",
      "INN: 5047118550    number of occurances in training dataset (all clusters): 0\n",
      "INN: 7704274402    number of occurances in training dataset (all clusters): 0\n"
     ]
    }
   ],
   "source": [
    "# create list of predicted inns of all trades assigned to all clusters\n",
    "predicted_INNs_total = list(df['CONSIGNOR_INN'])\n",
    "\n",
    "# create 'for' loop to see how manny times know INNs show up in predicted_INNs list\n",
    "# some INNS are very present in clusters 4 and 7, others not so much\n",
    "# expanding list of known arms exporters would be very helpful for this portion\n",
    "for i in inn_arms_exp_total:\n",
    "    print(\"INN:\", i, \"  \" ,\"number of occurances in training dataset (all clusters):\", predicted_INNs_total.count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Analysis\n",
    "We then totaled the trade-count-per-cluster for ALL known Russian Arms exporters, transposed it, and saved it to a dataframe.  This transposed dataset will be used as the final comparision in our product.  For example:\n",
    "\n",
    "| Cluster% | Known Arms Exporters% | INN in Dataset% |\n",
    "| --- | --- | --- |\n",
    "| % of trades falling into cluster0 | 30% | 26% |\n",
    "| % of trades falling into cluster1 | 12% | 6% |\n",
    "| % of trades falling into cluster2 | 5% | 15% |\n",
    "| % of trades falling into cluster3 | 5% | 0% |\n",
    "| % of trades falling into cluster4 | 5% | 2% |\n",
    "| % of trades falling into cluster5 | 20% | 18% |\n",
    "| % of trades falling into cluster6 | 5% | 3% |\n",
    "| % of trades falling into cluster7 | 1% | 12% |\n",
    "| % of trades falling into cluster8 | 3% | 0% |\n",
    "| % of trades falling into cluster9 | 5% | 15% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster\n",
       "0    55151\n",
       "1     9961\n",
       "6     8723\n",
       "7     1356\n",
       "8      348\n",
       "2       81\n",
       "3       42\n",
       "5       23\n",
       "4       13\n",
       "9        0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create subset of dataframe containing trade corpuses of known arms exporters only\n",
    "X = df[df['CONSIGNOR_INN'].isin(inn_arms_exp_total)]\n",
    "\n",
    "# Convert known arms exporter data\n",
    "listArmcluster = pd.DataFrame(X.cluster.value_counts())\n",
    "# add 0 value for cluster 9 index, as no known arms exporter trades fell into cluster 9\n",
    "listArmcluster.loc[9]=0\n",
    "listArmcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONSIGNOR_INN</th>\n",
       "      <th>clust0</th>\n",
       "      <th>clust1</th>\n",
       "      <th>clust2</th>\n",
       "      <th>clust3</th>\n",
       "      <th>clust4</th>\n",
       "      <th>clust5</th>\n",
       "      <th>clust6</th>\n",
       "      <th>clust7</th>\n",
       "      <th>clust8</th>\n",
       "      <th>clust9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>known_AE_trade_count</td>\n",
       "      <td>55151</td>\n",
       "      <td>9961</td>\n",
       "      <td>81</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>8723</td>\n",
       "      <td>1356</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CONSIGNOR_INN  clust0  clust1  clust2  clust3  clust4  clust5  \\\n",
       "1  known_AE_trade_count   55151    9961      81      42      13      23   \n",
       "\n",
       "   clust6  clust7  clust8  clust9  \n",
       "1    8723    1356     348       0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arms cluster fixing\n",
    "listArmcluster = listArmcluster.sort_index().reset_index()\n",
    "listArmcluster = listArmcluster.rename(columns={'index': \"cluster\", 'cluster': \"known_AE_trade_count\"})\n",
    "listArmcluster = listArmcluster.T.reset_index().rename(columns={'index':'CONSIGNOR_INN', 0:'clust0', 1:'clust1', 2:'clust2',\n",
    "                                                    3:'clust3', 4:'clust4', 5:'clust5', 6:'clust6',7:'clust7', 8:'clust8', 9:'clust9'}).rename_axis('', axis=1)\n",
    "listArmcluster = listArmcluster.drop([0])\n",
    "\n",
    "# 'profile' for russian arms exporters\n",
    "listArmcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export listAllcluster to S3 bucket\n",
    "listArmcluster.to_csv('s3://labs20-arms-bucket/data/armsclustersf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
